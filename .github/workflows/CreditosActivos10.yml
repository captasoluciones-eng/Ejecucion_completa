name: Ejecutar CreditosActivos10

on:
  workflow_dispatch:   # Ejecutarlo manualmente
  schedule:
    - cron: "0 * * * *"  # Cada hora (UTC)

jobs:
  run-creditosactivos10:
    runs-on: ubuntu-latest

    steps:
      # --------------------------------------------------
      # 1Ô∏è‚É£ Descargar el repositorio
      # --------------------------------------------------
      - name: üì• Checkout repository
        uses: actions/checkout@v3

      # --------------------------------------------------
      # 2Ô∏è‚É£ Configurar Python
      # --------------------------------------------------
      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      # --------------------------------------------------
      # 3Ô∏è‚É£ Instalar dependencias
      # --------------------------------------------------
      - name: üì¶ Instalar dependencias necesarias
        run: |
          python -m pip install --upgrade pip
          pip install pandas gdown google-cloud-bigquery pyarrow

      # --------------------------------------------------
      # 4Ô∏è‚É£ Configurar credenciales de Google Cloud
      # --------------------------------------------------
      - name: üîë Configurar credenciales GCP
        run: |
          echo "${{ secrets.GCP_CREDENTIALS }}" > $HOME/gcp_credentials.json
        env:
          GCP_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}

      # --------------------------------------------------
      # 5Ô∏è‚É£ Ejecutar script directamente en memoria
      # --------------------------------------------------
      - name: üöÄ Ejecutar CreditosActivos10.py (memoria)
  env:
    GOOGLE_APPLICATION_CREDENTIALS: $HOME/gcp_credentials.json
  run: |
    python3 << EOF
    import os
    import pandas as pd
    import gdown
    from io import BytesIO
    from google.cloud import bigquery

    print(f"üîë Autenticando con credenciales: {os.getenv('GOOGLE_APPLICATION_CREDENTIALS')}")
    client = bigquery.Client()

    # Descargar CSV en memoria
    file_id = "1Tu1__f_w-s7V2UCyP5RFVNRMFtnJ0zfE"
    url_csv = f"https://drive.google.com/uc?id={file_id}"
    print("üì• Descargando CSV...")
    csv_bytes = gdown.download(url_csv, output=None, quiet=False)
    csv_buffer = BytesIO(csv_bytes)

    # Leer CSV
    df = pd.read_csv(csv_buffer, sep=",", on_bad_lines="skip", low_memory=False, encoding="utf-8-sig")
    df.columns = df.columns.str.strip().str.replace(" ", "_").str.replace(r"[^a-zA-Z0-9_]", "", regex=True)
    print(f"‚úÖ CSV le√≠do correctamente. Filas: {len(df)} | Columnas: {len(df.columns)}")

    # Subir a BigQuery
    proyecto_bq = "lookerstudio-consolidacion"
    dataset_bq = "DatosLooker_USC"
    tabla_bq = "Full"
    tabla_destino = f"{proyecto_bq}.{dataset_bq}.{tabla_bq}"

    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE", autodetect=True)
    job = client.load_table_from_dataframe(df, tabla_destino, job_config=job_config)
    job.result()
    print(f"‚úÖ Datos subidos correctamente a {tabla_destino}")
    EOF

      # --------------------------------------------------
      # 6Ô∏è‚É£ Confirmaci√≥n final
      # --------------------------------------------------
      - name: ‚úÖ Confirmar finalizaci√≥n
        run: echo "üéâ Script CreditosActivos10 finalizado correctamente"
